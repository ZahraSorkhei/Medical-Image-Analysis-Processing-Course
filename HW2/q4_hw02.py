# -*- coding: utf-8 -*-
"""Q4-HW02.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ObyvSfGY2oQ2W9ZM2jEYFdMob-47R1pS

### Q4

#### Libraries
"""

import cv2
import numpy as np
from matplotlib import pyplot as plt
from skimage.color import rgb2gray
from skimage.io import imread

"""#### Reading Images and Matching Size"""

image_one = imread("res19-near.jpg")
image_two = imread("res20-far.jpg")
# Get the smaller image size
height1, width1,_ = image_one.shape
height2, width2,_ = image_two.shape
min_height = min(height1, height2)
min_width = min(width1, width2)
image_one = cv2.resize(image_one, (min_width, min_height))
image_two = cv2.resize(image_two, (min_width, min_height))

plt.figure(figsize = (5,5))
plt.imshow(image_one)
plt.imshow(image_two, alpha=0.5)
plt.axis('off')

"""#### Mapping Images"""

def align_images(img_one, img_two):
    h1, w1,_ = img_one.shape
    h, w,_ = img_two.shape
    src_points = np.array(
        [[322, 479], [595, 485], [157, 412], [775, 416],  [0, 0], [0, h1 - 1],
         [w1 - 1, 0], [w1 - 1, h1 - 1]], dtype=float)
    dst_points = np.array(
        [[335, 505], [555, 500], [172, 414], [763, 424],  [0, 0], [0, h - 1],
         [w - 1, 0], [w - 1, h - 1]], dtype=float)
    transform, f = cv2.findHomography(src_points, dst_points)
    img_one = cv2.warpPerspective(img_one, transform, (w, h))
    return img_one

image_one = align_images(image_one, image_two)

plt.figure(figsize = (5,5))
plt.imshow(image_one)
plt.imshow(image_two, alpha=0.5)
plt.axis('off')

plt.figure(figsize = (5,5))
plt.imshow(image_one)
plt.axis('off')
plt.savefig('wavelet-near-aligned.jpg')

plt.figure(figsize = (5,5))
plt.imshow(image_two)
plt.axis('off')
plt.savefig('wavelet-far-aligned.jpg')

"""#### Inverse Descrete Wavelet Transform On Each image"""

image1  = np.asarray(image_one).astype('int')
image2  = np.asarray(image_two).astype('int')

# Import the pywt module
import pywt

def getTransformeImage(img, mode = 'db1',filter='low'):
      # Perform 2D discrete wavelet transform (DWT) on the image
      # using Daubechies wavelet 'db1'
      coeffs = pywt.dwt2(img, 'db1')

      # The coeffs variable contains four subbands: 
      # approximation (LL), horizontal (LH), vertical (HL) and diagonal (HH)
      LL, (LH, HL, HH) = coeffs

      # To perform lowpass filtering, we can keep only the approximation subband
      # and set the other subbands to zero
      if(filter == 'low'):
          LH = LH - LH
          HL = HL - HL
          HH = HH - HH

      elif(filter == 'high'):
          LL = LL - LL
          HL = HL - HL
          LH = LH - LH

      # Reconstruct the image from the modified coefficients
      filtered_image = pywt.idwt2((LL, (LH, HL, HH)), 'db1')

      return filtered_image

LL1 = []
LH1 = []
HL1 = []
HH1 = []
for i in range(3):
      coeffs = pywt.dwt2(image1[:,:,i], 'db1')

      # The coeffs variable contains four subbands: 
      # approximation (LL), horizontal (LH), vertical (HL) and diagonal (HH)
      LL, (LH, HL, HH) = coeffs
      LL1.append(LL)
      LH1.append(LH)
      HL1.append(HL)
      HH1.append(HH)
LL1 = np.asarray(LL1).transpose(1, 2, 0)
LH1 = np.asarray(LH1).transpose(1, 2, 0)
HL1 = np.asarray(HL1).transpose(1, 2, 0)
HH1 = np.asarray(HH1).transpose(1, 2, 0)
fig = plt.figure(figsize=(10, 10))
rows = 2
columns = 2
fig.add_subplot(rows, columns, 1)
plt.imshow(LL1.astype('int') )
plt.title('LL')
plt.axis('off')
fig.add_subplot(rows, columns, 2)
plt.imshow(LH1.astype('uint8') )
plt.title('LH')
plt.axis('off')
fig.add_subplot(rows, columns, 3)
plt.imshow(HL1.astype('uint8') )
plt.title('HL')
plt.axis('off')
fig.add_subplot(rows, columns, 4)
plt.imshow(HH1.astype('uint8')  )
plt.title('HH')
plt.axis('off')
plt.savefig('wavelet-near-dwt.jpg')

LL2 = []
LH2 = []
HL2 = []
HH2 = []
for i in range(3):
      coeffs = pywt.dwt2(image2[:,:,i], 'db1')

      # The coeffs variable contains four subbands: 
      # approximation (LL), horizontal (LH), vertical (HL) and diagonal (HH)
      LL, (LH, HL, HH) = coeffs
      LL2.append(LL)
      LH2.append(LH)
      HL2.append(HL)
      HH2.append(HH)
LL2 = np.asarray(LL2).transpose(1, 2, 0)
LH2 = np.asarray(LH2).transpose(1, 2, 0)
HL2 = np.asarray(HL2).transpose(1, 2, 0)
HH2 = np.asarray(HH2).transpose(1, 2, 0)
fig = plt.figure(figsize=(10, 10))
rows = 2
columns = 2
fig.add_subplot(rows, columns, 1)
plt.imshow(LL2.astype('int') )
plt.title('LL')
plt.axis('off')
fig.add_subplot(rows, columns, 2)
plt.imshow(LH2.astype('uint8') )
plt.title('LH')
plt.axis('off')
fig.add_subplot(rows, columns, 3)
plt.imshow(HL2.astype('uint8') )
plt.title('HL')
plt.axis('off')
fig.add_subplot(rows, columns, 4)
plt.imshow(HH2.astype('uint8')  )
plt.title('HH')
plt.axis('off')
plt.savefig('wavelet-far-dwt.jpg')

"""#### Combine Images"""

def combineImages(img1, img2):
      # Perform 2D discrete wavelet transform (DWT) on the image
      # using Daubechies wavelet 'db1'
      coeffs1 = pywt.dwt2(img1, 'db1')
      coeffs2 = pywt.dwt2(img2, 'db1')

      # The coeffs variable contains four subbands: 
      # approximation (LL), horizontal (LH), vertical (HL) and diagonal (HH)
      LL1, (LH1, HL1, HH1) = coeffs1
      LL2, (LH2, HL2, HH2) = coeffs2

      # Reconstruct the image from the modified coefficients
      filtered_image = pywt.idwt2((LL2*0.6+LL1*0.4, ((LH1*0+LH2*0), (HL1*0+HL2*0), HH1*0.8+HH2*0.2)), 'db1')

      return filtered_image

result = image1 - image1
result[:,:,0] = combineImages(image1[:,:,0],image2[:,:,0])[:,:-1]
result[:,:,1] = combineImages(image1[:,:,1],image2[:,:,1])[:,:-1]
result[:,:,2] = combineImages(image1[:,:,2],image2[:,:,2])[:,:-1]

plt.imshow(result.astype(np.uint8))
plt.axis('off')
plt.savefig('wavelet-hybrid.jpg')
plt.show()

result_low = result-result
result_low[:,:,0] = getTransformeImage(result[:,:,0])[:,:-1]
result_low[:,:,1] = getTransformeImage(result[:,:,1])[:,:-1]
result_low[:,:,2] = getTransformeImage(result[:,:,2])[:,:-1]
plt.imshow(result_low.astype(np.uint8))
plt.axis('off')
plt.savefig('wavelet-hybrid-near.jpg')
plt.show()

result_high = result-result
result_high[:,:,0] = getTransformeImage(result[:,:,0],filter='high')[:,:-1]
result_high[:,:,1] = getTransformeImage(result[:,:,1],filter='high')[:,:-1]
result_high[:,:,2] = getTransformeImage(result[:,:,2],filter='high')[:,:-1]
plt.imshow(result_high.astype(np.uint8))
plt.axis('off')
plt.savefig('wavelet-hybrid-far.jpg')
plt.show()

"""To combine two images using wavelet transform, we first get the wavelet transform coefficients for both images. Then we set the low-high and high-low coefficients to zero for both of them. Since low-low has a lot of information for both images, we collect 40% of the low frequencies of the close image and 60% of the low frequencies of the far image. For high frequencies, we take 30% of the high frequencies of the far image and 70% of the high frequencies of the near image. We do not completely remove either low or high frequency from either image because doing so would make one image invisible."""